[
["intro.html", "Slow ggplot2 Chapter 1 Introduction", " Slow ggplot2 Evangeline Reynolds 2018-09-29 Chapter 1 Introduction In late 2016 I heard Andy Kreibel (and __) being interviewed on the Podcast “Data Stories”. He was invited onto the show because he had started the initiative #MakeoverMonday, in which he would find the data for an existing data visualization that he had come across in the media, and would recreate the visualization using Tableau, a tool that they were both expert in, but found that they weren’t practicing as regularly due to the grind of administrative jobs. The two friends shared their makeovers products with each other, but also with the world on Twitter. Soon, more people expressed interest in joining, and they two started a more organized initiative - posting the original graph and data every Sunday, so that whoever wanted to could participate in #Makeovermonday. My first submission was late 2016, after catching wind of the exciting project via the podcast. I made a scrappy little graph about motorway casualties; sad topic, but fun graph making. I was using base R at that time. Then in the summer of 2017 I went to a conference in Zurich, the women’s summer school for political methodology. There was a session on ggplot2. I internalized some of the basics, and decided that if I wanted to learn that (powerful - as everyone kept calling it) graphing system, then I could do it via the #MakeoverMonday weekly exercises (not that I particpated weekly). Even though most folks were using Tablaeu, the administrators didn’t seem to mind a few R and ggplot submission here and there. I got a little hooked. Early this year Andy and Eva Murry sent a number of the participants a private message on Twitter. “We’re writing a book: #MakeoverMonday”. They were putting together a collection of a visualizations that resulted from the project, and were seeking perspectives of participants as well as permission to use some of the visualizations produced for the initiatives. Cool. I was pleased to participate. For me #MakeoverMonday allowed me to focus on the visualization task. Usually visualization comes at the end of, sometimes arguous, data cleaning — and you might already be a little spent. Having rather clean data delivered, and seeing the approaches of many other (many brilliant) data visualizers was a treat. I still need to buy my copy of the book, which contains a visualization of food prices in London as a function of how far a restaurant is from the Big Ben. And now, using the magic of RStudio and Yihui Xie’s bookdown, I’m putting together my own little collection. Of course there is a bit of curation involved — I’m not including every plot. And, I’m revising the exact code that creates the plots in many cases, to be more consistent across plots, and also, I think, to make communicating about how the plot was built easy. This involves: using fewer functions (labs(title = ) instead of ggtitle()) pulling out aes() from the ggplot() function multiply using functions aes(x = ?) + aes(y = ?) rather than aes(x = , y = ) using base R functions and tidyverse functions. For other packages, the :: style to call them write out arguments (no shortcuts) aes(x = gdppercap) not aes(gdppercap) order ggplot commands so that reactivity is obvious "],
["baseball-war-and-ethnicity.html", "Chapter 2 Baseball, WAR, and Ethnicity", " Chapter 2 Baseball, WAR, and Ethnicity This data visualization uses the WAR measure in baseball, a calculation based on the contributions of players. The visualizations show that new ethnicities and races started to be included in Major League baseball, the minority players that joined tended to contribute more than the expected value for players overall. For example, from 1947, when Jackie Robinson joined Major League baseball, and onward, the percent of African American players was outpaced by the percent calculated contributions (WAR) of African American players. A random sample from the data set: Year Ethnicity type Percent 1976 White % of Players 70.5 1984 Asian % of Players 0.0 1950 African American % of Players 1.7 1947 Asian % of WAR 0.0 2011 Latino % of Players 26.9 ggplot(df_gather) + aes(x = Year) + aes(y = Percent) + aes(fill = type) + facet_wrap(~ Ethnicity) + geom_area(alpha = .5, position = &quot;dodge&quot;) + labs(fill = &quot;&quot;) + labs(x = &quot;&quot;) + labs(title = &quot;American Baseball Demographics 1947-2016&quot;) + labs(subtitle = &quot;Percentage of players and WAR percentage (WAR is a calculation of value contributed)\\nData: SABR.org | Vis: @EvaMaeRey for #MakeoverMonday&quot;) + theme_light() "],
["christmas-trees.html", "Chapter 3 Christmas Trees", " Chapter 3 Christmas Trees Here is a simple plot of Christmas Tree Sales in the U.S. The plot shows that artificial tree sales are on the rise, contrasting with declines in real trees. The title plays on the German Christmas Carol “O Tannenbaum”, “Oh Christmas Tree” in English. “Wie echt sind deine Blätter?” means “how real are your leaves”; the original text from the carol is “Wie treu sind deine Blätter!” which means “How true your leaves are!” I also plot the cumulative number of trees purchased of each type, artificial and real, from 2004 to 2014, comparing that to the 2016 U.S. population. Almost one real tree per person was bought over the course of 10 years! A random sample from the data set: Year Number of trees sold Type of tree Number of trees sold (millions) 2014 13900000 Fake tree 13.9 2009 11700000 Fake tree 11.7 2012 24500000 Real tree 24.5 2015 12500000 Fake tree 12.5 2010 27000000 Real tree 27.0 ggplot(data = dta) + aes(Year) + aes(y = `Number of trees sold (millions)`) + geom_point() + aes(col = fct_rev(`Type of tree`)) + geom_smooth(method = &quot;lm&quot;, se = F) + scale_color_manual(values = c(&quot;darkgreen&quot;, &quot;green&quot;)) + ylim(c(0, 35)) + labs(col = &quot;&quot;) + labs(title = &quot;Wie echt sind deine Blätter?&quot;) + labs(subtitle = &quot;Real and fake Christmas trees sold in the US | Data Source: Statista | @EvaMaeRey &quot;) + theme_bw() dta &lt;- dta %&gt;% group_by(`Type of tree`) %&gt;% mutate(cumula = cumsum(`Number of trees sold (millions)`)) ggplot(dta %&gt;% filter(Year &lt;= 2014)) + aes(Year) + aes(y = cumula) + aes(fill = `Type of tree`) + geom_hline(yintercept = 323.1, lty = 2) + geom_area(alpha = .2) + facet_wrap(~ `Type of tree`) + annotate(geom = &quot;text&quot;, x = 2010, y = 335, label = &quot;US Population (2016)&quot;) + labs(title = &quot;Ten years of trees.&quot;) + labs(subtitle = &quot;Cummulative real and fake Christmas trees sold in the US\\nData Source: Statista | @EvaMaeRey &quot;) + scale_fill_manual(values = c(&quot;green&quot;, &quot;darkgreen&quot;)) + theme_bw() + ylim(c(0, 400)) "],
["officials-beliefs-about-womens-representation.html", "Chapter 4 Officials’ beliefs about women’s representation", " Chapter 4 Officials’ beliefs about women’s representation The data provided is based on a small survey of elite officials in five less developed countries. The question that arrises from the data is: How well do elites know the conditions in their countries. In general, the elites overestimate women’s representation. But this is not the case in Senegal, where there are gender quotas in the Parliament. Most elites therefore estimate that the representation is about equal with men. I jitter the responses of the elites horizontally to avoid overplotting. A random sample from the data set: Country Topic value value_type alpha Colombia Share of seats held by women 0.33 Individual belief 0.3 Senegal Share of seats held by women 0.46 Individual belief 0.3 India Share of seats held by women 0.15 Individual belief 0.3 Indonesia Share of seats held by women 0.10 Individual belief 0.3 Senegal Share of seats held by women 0.50 Individual belief 0.3 ggplot(data = df_all) + aes(x = Country) + aes(y = value) + aes(col = fct_inorder(value_type)) + aes(alpha = fct_inorder(value_type)) + aes(shape = fct_inorder(value_type)) + geom_jitter(width = .1, height = 0, size = 7) + geom_hline(yintercept = c(0, 100), col = &quot;grey&quot;) + geom_hline(yintercept = c(50), lty = 2, col = &quot;grey&quot;) + theme_bw(base_size = 20, base_family = &quot;Times&quot;) + scale_y_continuous(limits = c(0, 1), expand = c(0, 0), labels = scales::percent) + # create just one key &quot;&quot; mixing aesthetics scale_colour_manual(name = &quot;&quot;, values = c(&quot;darkblue&quot;, &quot;goldenrod3&quot;, &quot;goldenrod3&quot;)) + scale_alpha_manual(name = &quot;&quot;, values = c(1, .17, 1)) + scale_shape_manual(name = &quot;&quot;, values = c(8, 19, 8)) + annotate(geom = &quot;text&quot;, x = 4.95, y = .70, label = str_wrap(&quot;Senegal&#39;s 2010 gender parity law means it leads among these countries.&quot;, 16), size = 5, hjust = 1) + annotate(geom = &quot;text&quot;, x = 5.05, y = .250, label = str_wrap(&quot;Officials seem to be aware of the law.&quot;, 10), size = 5, hjust = 0) + labs(x = &quot;&quot;) + labs(y = &quot;Seats held by women&quot;) + labs(title = &quot;Women in national parliaments in 2015 in five countries \\nand officials&#39; beliefs about representation&quot;) + labs(subtitle = &quot;Data Source: Equal Measures 2030 | Vis: Gina Reynolds @EvaMaeRey&quot;) "],
["maternal-leave.html", "Chapter 5 Maternal Leave", " Chapter 5 Maternal Leave The OECD provides a comparative report on how much paid leave women are entitled to after childbirth. But leave takes different forms. In some places, the allowed leave is longer, but sometimes that means that the pay out compared to the regular salary is lower. To emphasize the different forms that law around paid leave take, I plotted the total payout available to mothers as areas of rectangles, where one side is the length of leave allowed, and the other side is the proportion of salary paid to the new mom. A random sample from the data set: Country Paid maternity leave avg payment rate (%) Paid maternity leave full rate equivalent in weeks Paid maternity leave in weeks Paid parental leave avg payment rate (%) Paid parental leave full rate equivalent in weeks Paid parental leave in weeks Total paid leave avg payment rate (%) Total paid leave full rate equivalent in weeks Total paid leave in weeks rank_name paid_leave_months total_paid_yearly_salaries Switzerland 56.4 7.9 14.0 0.0 0.0 0.0 56.4 7.9 14.0 #32: Switzerland 3.221918 0.1519231 Sweden 77.6 10.0 12.9 57.7 24.7 42.9 62.3 34.7 55.7 #13: Sweden 12.818630 0.6673077 Denmark 53.6 9.6 18.0 53.6 17.1 32.0 53.6 26.8 50.0 #16: Denmark 11.506849 0.5153846 United Kingdom 30.9 12.1 39.0 0.0 0.0 0.0 30.9 12.1 39.0 #28: United Kingdom 8.975343 0.2326923 Estonia 100.0 20.0 20.0 44.5 65.0 146.0 51.2 85.0 166.0 #1: Estonia 38.202740 1.6346154 ggplot(df) + aes(x = paid_leave_months) + aes(y = `Total paid leave avg payment rate (%)`) + aes(xmin = 0) + aes(xmax = paid_leave_months) + aes(ymin = 0) + aes(ymax = `Total paid leave avg payment rate (%)`) + facet_wrap(fct_inorder(rank_name) ~ .) + geom_rect(fill = &quot;blue&quot;, alpha = .2) + aes(yend = 0) + aes(xend = 0) + geom_segment(aes(yend = `Total paid leave avg payment rate (%)`), lty = &quot;dashed&quot;) + geom_segment(aes(xend = paid_leave_months), lty = &quot;dashed&quot;) + scale_y_continuous(limits = c(0, 100), expand = c(0, 0), breaks = c(0, 50, 100)) + scale_x_continuous(limits = c(0, 44), expand = c(0, 0)) + labs(x = &quot;Length of paid leave entitlement (months)&quot;) + labs(y = &quot;Percent of income paid (average over entitlement period)&quot;) + labs(title = &quot;Total paid leave available to mothers in the OECD&quot;) + labs(subtitle = &quot;Countries rank ordered by paid leave full rate equivalent (blue rectangular area)\\nVisualization: Gina Reynolds | Data source: OECD.org &quot;) + theme_bw(base_size = 12) "],
["traits.html", "Chapter 6 Traits", " Chapter 6 Traits A random sample from the data set: Gender Question_short Rank (text) Rank (number) n Percent Women Personality Ranked fifth 5 608.01 5.331190 Women Personality Ranked fourth 4 945.87 8.293635 Men Has similar interests Ranked fifth 5 2609.06 24.430224 Women Sense of humor Ranked first 1 1595.04 14.024450 Women Has similar interests Ranked first 1 1442.49 12.655053 ggplot(data = world) + aes(x = Question_short_wrap) + aes(y = Percent) + aes(fill = `Rank (text)`) + facet_grid(Gender ~ .) + geom_col() + coord_flip() + scale_fill_manual( values = colorRampPalette(RColorBrewer::brewer.pal(9, &quot;Purples&quot;))(6)[1:6], guide = guide_legend(reverse = TRUE) ) + labs(fill = &quot;&quot;) + xlab(&quot;&quot;) + labs(title = &quot;Why do I love thee? Let me rank the traits... \\nHow 10,689 men and 11,370 women across 20 countries rank romantic partner trait importance&quot;) + labs(subtitle = &quot;Data Source: @mattsmithetc and @YouGov | Design: Gina Reynolds&quot;) "],
["salarys-of-trump-and-obama-white-house-employees.html", "Chapter 7 Salarys of Trump and Obama White House Employees", " Chapter 7 Salarys of Trump and Obama White House Employees The data set, originally reported on in an NPR article, shows the difference in the distribution of salaries for the Obama and early Trump White House. First I plot a histogram of each administration. Then I also contrast boxplots for each administration; the data points are overlayed, jittered to the widths of the boxplots. Plotly is used to make the graph interactive; mousing over will allow you to see who the point represents, their job description and exactly how much they are paid. A random sample from the data set: ADMINISTRATION NAME STATUS SALARY PAY BASIS POSITION TITLE Obama Zients, Jeffrey D. Employee 176461 Per Annum ASSISTANT TO THE PRESIDENT FOR ECONOMIC POLICY AND DIRECTOR OF THE NATIONAL ECONOMIC COUNCIL Trump Blase, Brian C. Employee 115000 Per Annum SPECIAL ASSISTANT TO THE PRESIDENT FOR ECONOMIC POLICY Trump Rateike, Bradley A. Employee 94000 Per Annum DIRECTOR OF CABINET COMMUNICATIONS Obama Hsu, Irene Employee 62100 Per Annum POLICY ADVISOR Trump Braid, Duncan M. Employee 47000 Per Annum RESEARCH ASSOCIATE ggplot(both_data) + aes(x = ADMINISTRATION) + aes(y = SALARY) + geom_jitter(alpha = .5, height = 0, width = .25) + aes(col = ADMINISTRATION) + geom_boxplot(alpha = .25) + aes(fill = ADMINISTRATION) + scale_colour_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) + scale_fill_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) + theme_bw() "],
["winter-games.html", "Chapter 8 Winter Games", " Chapter 8 Winter Games A random sample from the data set: Year Sport Event Country Gender Medal Rank Medal Name of Athlete or Team Age of Athlete 1976 Biathlon Men’s 20 Kilometers Soviet Union Men 1 gold Nikolay Kruglov 26 1998 Cross-Country Skiing Men’s 10 Kilometers Finland Men 3 bronze Mika MyllylÃ¤ 28 1948 Speedskating Men’s 500 Meters United States Men 2 silver Ken Bartholomew 27 1976 Bobsled Men’s Two East Germany Men 1 gold East Germany-2 NA 2006 Curling Women’s Curling Sweden Women 1 gold Sweden NA ggplot(data = dta) + aes(x = Year) + aes(y = percent_medals) + geom_line() + facet_wrap(~ Country) A random sample from the data set: Year Sport Event Country Gender Medal Rank Medal Name of Athlete or Team Age of Athlete cold_war 1956 Cross-Country Skiing Women’s 10 Kilometers Soviet Union Women 2 silver Radiya Yeroshina 25 Soviet Union 1972 Cross-Country Skiing Men’s 50 Kilometers Soviet Union Men 3 bronze Vyacheslav Vedenin 30 Soviet Union 1984 Alpine Skiing Men’s Slalom France Men 3 bronze Didier Bouvet 22 A 2002 Luge Women’s Singles Germany Women 3 bronze Silke Kraushaar 31 A 1998 Cross-Country Skiing Men’s 10 Kilometers Norway Men 1 gold BjÃ¸rn DÃ¦hlie 30 A ggplot(dta) + aes(x = Year) + aes(y = `Age of Athlete`) + facet_wrap(~ Sport, scales = &quot;free_y&quot;, nrow = 2) + geom_jitter(size = 1, mapping = aes(col = fct_inorder(Medal))) + geom_smooth(col = &quot;grey30&quot;) + geom_ribbon(ymin = 20, ymax = 30, alpha = .1, fill = &quot;blue&quot;) + geom_hline(yintercept = c(20, 30), lty = &quot;dotted&quot;) + geom_hline(yintercept = c(25), lty = &quot;dashed&quot;) + scale_color_manual(values = c(&quot;goldenrod3&quot;, &quot;grey40&quot;, &quot;goldenrod4&quot;), name = &quot;&quot;) + labs(x = &quot;&quot;) + labs(title = &quot;Young and old at the Winter Olympics: medalists&#39; declared ages have risen in recent years&quot;) + labs(subtitle = &quot;Includes individual sports that have been in Olympic since 1965&quot;) + labs(caption = &quot;Source: Sports-Reference.com | Vis: Gina Reynolds @EvaMaeRey \\nValues &#39;jittered&#39; to reduce overplotting&quot;) + theme_bw(base_size = 13) "],
["brexit.html", "Chapter 9 Brexit", " Chapter 9 Brexit This visualization challenge was a proposed makeover for a Financial Times visualization focusing on relative economic growth in G7 countries, with an emphasis on growth in the UK, focusing especially since Brexit. The visualization I present here is not what I created at the time of the challenge; instead it is inspired by Alan Smith a data journalist at the Financial Times, who created a really compelling visualization a couple of months after MakeoverMonday’s treatment. I try to recreate his plot - which uses a ribbon to contain all G7 countries, and plot the UK’s stats thereover. This declutters the graph, and makes you focus on where the UK falls among other countries, without being needlessly specific about those countries; the data story isn’t about them anyway, might be Smith’s thinking. My graph actually lightly traces economic growth in other countries, but deemphasizes their importance, like Smith. A random sample from the data set: Country Year Quarter Date (start of quarter) Percentage change from previous period Date (start o quarter) USA 2013 3 2013-07-01 0.771183 2013-07-01 ITA 2014 3 2014-07-01 0.146421 2014-07-01 ITA 2014 2 2014-04-01 -0.046314 2014-04-01 USA 2011 4 2011-10-01 1.126416 2011-10-01 GBR 2015 2 2015-04-01 0.480852 2015-04-01 ggplot(data = data) + aes(x = `Date (start of quarter)`) + aes(y = `Percentage change from previous period`) + facet_wrap(~ Country) + geom_line() + geom_hline(yintercept = 0, col = &quot;grey&quot;) + geom_vline(xintercept = as.numeric(as.POSIXct(&quot;2016-06-23&quot;)), lty = &quot;dashed&quot;) + labs(title = &quot;Quarterly GDP Growth in Relation to Brexit Vote&quot;) + labs(subtitle = &quot;Source: OECD&quot;) A random sample from the data set: Country Year Quarter Date (start of quarter) Percentage change from previous period Date (start o quarter) min_ max_ CAN 2011 3 2011-07-01 1.387897 2011-07-01 -0.468615 2.312151 FRA 2012 2 2012-04-01 -0.113871 2012-04-01 -0.790043 0.466941 FRA 2015 1 2015-01-01 0.378716 2015-01-01 -0.248989 1.129767 FRA 2016 1 2016-01-01 0.564609 2016-01-01 0.145036 0.681367 FRA 2012 4 2012-10-01 -0.093296 2012-10-01 -0.636122 0.125654 ggplot(data = data) + aes(x = `Date (start of quarter)`) + aes(y = `Percentage change from previous period`) + aes(ymin = min_) + aes(ymax = max_) + geom_hline(yintercept = 0, col = &quot;grey&quot;) + geom_ribbon(alpha = .2) + geom_line(aes(col = Country), alpha = .2) + geom_line(data = data %&gt;% filter(Country == &quot;GBR&quot;), col = &quot;black&quot;) + geom_vline(xintercept = as.numeric(as.POSIXct(&quot;2016-06-23&quot;)), lty = 2) + annotate( geom = &quot;text&quot;, x = as.POSIXct(&quot;2016-04-23&quot;), y = 1.5, label = &quot;Brexit Vote&quot;, angle = 90 ) + labs( title = &quot;Quarterly GDP Growth of G7 in Relation to Brexit Vote&quot;, subtitle = &quot;Source: OECD&quot;, col = &quot;&quot; ) + theme_bw() "],
["curry-in-london.html", "Chapter 10 Curry in London", " Chapter 10 Curry in London This visualization task seemed to get at the question: Does where you eat matter. The data was the cost of identical menu items at different locations of the same restaurant, the Wetherspoon, around the UK. First, I mapped the cost of a single menu item, the Empire Burger, across the UK. Then, I calculated the distance from Wetherspoon restaurants from the Big Ben, and plotted prices as a function of this distance – plotting only the restaurants in a 10 kilometer radius. A random sample from the data set: Name Location Latitude Longitude Empire State Burger Chicken Tikka Gammon afternoon deal Chocolate Brownie Doom Bar Birra Moretti Porn Star at 2 x £12 Porn Star (glass) MEAL Notes Moretti as a % of a tikka Moretti as % of burger PRICE BUCKETS Food cost £ Drink cost £ The Falcon High Wycome 51.62923 -0.7512765 8.75 7.90 5.9 3.85 2.29 3.05 NA 5.85 25.84 NA 0.3860759 0.3485714 £25.21+ 16.65 5.34 The Shay Wake Oldham 53.57790 -2.0929616 8.75 7.90 5.9 3.85 2.29 3.05 6.3 NA 25.84 NA 0.3860759 0.3485714 £25.21+ 16.65 5.34 The Ford Maddox Brown Wilmslow Park 53.45816 -2.2267009 8.75 7.40 5.9 3.85 2.29 3.15 6.3 NA 25.44 NA 0.4256757 0.3600000 £25.21+ 16.15 5.44 George’s Meeting House Exeter 50.72062 -3.5299504 8.75 8.29 5.9 3.85 2.29 2.89 6.3 NA 26.07 NA 0.3486128 0.3302857 £25.21+ 17.04 5.18 The Ferry Boat Runcorn 53.34233 -2.7315021 8.75 7.40 5.9 3.85 2.19 2.95 6.3 NA 25.14 NA 0.3986486 0.3371429 £25.20- 16.15 5.14 # Mapping data world_map_df &lt;- map_data(&quot;world&quot;) A random sample from the data set: long lat group order region subregion 42668 25.22383 39.89258 643 42668 Greece Limnos 52873 55.42402 26.77056 847 52873 Iran NA 41746 -14.88672 10.96807 596 41746 Guinea NA 77020 150.75693 75.16240 1296 77020 Russia Ostrov Novaya Sibr’ 42476 20.35254 38.17988 633 42476 Greece Kefallinia # create a blank ggplot theme theme_opts &lt;- theme( panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank(), plot.background = element_rect(fill = &quot;#e6e8ed&quot;), panel.border = element_blank(), axis.line = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank(), axis.ticks = element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank(), plot.title = element_text(size = 15) ) ggplot(data = world_map_df %&gt;% filter(region == &quot;UK&quot;)) + aes(x = long) + aes(y = lat) + aes(group = group) + geom_polygon(fill = &quot;white&quot;) + coord_equal() + scale_fill_viridis_c(option = &quot;viridis&quot;) + geom_point(data = data0, mapping = aes(x = Longitude, y = Latitude, group = NULL, fill = `Empire State Burger`), colour = &quot;black&quot;, shape = 21, stroke = 1, alpha = .5, size = 3 ) + labs(fill = &quot;Price\\n(Pounds)&quot;) + labs(title = &quot;Empire State Burger Price&quot;) + labs(subtitle = &quot;@EvaMaeRey | source: data.worldbank.org&quot;) + theme_opts A random sample from the data set: Name Location Latitude Longitude Notes Moretti as a % of a tikka Moretti as % of burger PRICE BUCKETS Food cost £ Drink cost £ Kilometers from Big Ben Item Menu Item Price The Bishop Blaize Stretford 53.46126 -2.2891414 NA 0.4436718 0.3645714 £25.21+ 15.94 5.48 262.471887 Empire State Burger 8.75 Goldengrove Stratford, London 51.54377 0.0039464 NA 0.3987342 0.3600000 £25.21+ 16.65 5.50 9.165488 Empire State Burger 8.75 The Counting House Congleton 53.16386 -2.2146526 NA 0.4175676 0.3531429 £25.21+ 16.15 5.38 233.001988 Gammon afternoon deal 5.90 Goldengrove Stratford, London 51.54377 0.0039464 NA 0.3987342 0.3600000 £25.21+ 16.65 5.50 9.165488 Doom Bar 2.35 The Ivor Davies Cardiff 51.48131 -3.2003483 NA 0.4200000 0.3405405 £25.21+ 16.75 5.64 214.153117 Empire State Burger 9.25 ggplot(data = dataLong) + aes(x = `Kilometers from Big Ben`) + aes(y = `Menu Item Price`) + facet_wrap(~ Item, scales = &quot;free_y&quot;) + geom_point() + geom_smooth() + xlim(c(0, 10)) + labs(title = &quot;Wetherspoon Pubs&#39; Menu Item Prices v. Distance from Big Ben&quot;) + labs(subtitle = &quot;Visualization: Gina Reynolds | Source: Financial Times Alphaville&quot;) "],
["life-expectancy-increases.html", "Chapter 11 Life Expectancy Increases", " Chapter 11 Life Expectancy Increases To dramatically show the increases in life expectancy by country from 1960 to 2010, I plot the variable in 1960 versus itself in 2010. The line of equivilance (a 45% angle) is used as a reference and shows the result that you would see if there where no growth. The vertical distance from this line is the increase in life expectancy. I also superimpose a linear model on top of the scatter plot. You can see that the gains are greater for countries that started off with lower life expectancies. A random sample from the data set: Life Expectancy 1960 Country Code Country Name Region Income Group Year Life Expectancy 2010 CountryName squared 42.11832 BOL Bolivia Latin America &amp; Caribbean Lower middle income 2010 66.40580 Bolivia 1773.953 41.23605 BDI Burundi Sub-Saharan Africa Low income 2010 54.83700 Burundi 1700.412 39.57012 GAB Gabon Sub-Saharan Africa Upper middle income 2010 62.85654 Gabon 1565.795 NA MAF St. Martin (French part) Latin America &amp; Caribbean High income 2010 78.72195 Saint Martin (French part) NA NA GRL Greenland Europe &amp; Central Asia High income 2010 70.85707 Greenland NA ggplot(compare) + aes(x = `Life Expectancy 1960`) + aes(y = `Life Expectancy 2010`) + geom_point() + geom_smooth(se = F, method = &quot;lm&quot;) + geom_abline(slope = 1, intercept = 0, lty = 2) + # coord_fixed() + aes(xend = `Life Expectancy 1960`) + aes(yend = `Life Expectancy 1960`) + geom_segment(mapping = aes(col = &quot;Gain from 1960 to 2010&quot;)) + geom_segment(mapping = aes(y = 0, col = &quot;Country Expectancy in 1960&quot;)) + scale_color_manual( breaks = c( &quot;Gain from 1960 to 2010&quot;, &quot;Country Expectancy in 1960&quot; ), values = c(&quot;grey59&quot;, &quot;grey30&quot;, &quot;grey30&quot;) ) + geom_point(aes(y = `Life Expectancy 1960`), col = &quot;grey30&quot;) + geom_point() + labs(subtitle = &quot;@EvaMaeRey | source: data.worldbank.org&quot;, size = .7) + labs(title = &quot;Life Expectancy at Birth by Country&quot;) + labs(col = &quot;&quot;) + theme(legend.title = element_blank()) + theme_bw() + xlim(c(20, 80)) "],
["myers-briggs.html", "Chapter 12 Myers Briggs", " Chapter 12 Myers Briggs This data looks at the relationship betweeen four binary variables. The challenge is how to display that in one visualization. My first idea was to use a mosaic plot. However, I came across advice from “The Perceptual Edge”, that generally advised against the use of the mosaic plot, instead favoring a kind of nested bar plot. I tried to implement that. While I do think that it is pretty, I think that it still requires a lot of the reader to interpret the graph. Perhaps more annotation could alleviate this burden. A random sample from the data set: (S)ensing/I(N)tuition (T)hinking/(F)eeling (J)udging/(P)erceiving (E)xtroversion/(I)ntroversion count Sensing Thinking Perceiving Extroversion 1 Sensing Feeling Perceiving Extroversion 1 Sensing Thinking Perceiving Extroversion 1 Sensing Feeling Judging Extroversion 1 Sensing Feeling Judging Extroversion 1 ggplot(d) + aes(x = `(J)udging/(P)erceiving`) + aes(fill = `(T)hinking/(F)eeling`) + facet_grid(`(E)xtroversion/(I)ntroversion` ~ `(S)ensing/I(N)tuition`) + geom_rect(aes(x = NULL, y = NULL, xmin = mins, xmax = max, fill = `judging perceiving`), ymin = 0, ymax = 700, data = background ) + geom_bar(position = &quot;dodge&quot;) + scale_fill_manual(values = alpha(c(&quot;lightgrey&quot;, &quot;darkgrey&quot;, &quot;blue&quot;, &quot;violet&quot;), c(.3, .3, .6, .6))) + labs(x = &quot;&quot;) + labs(y = &quot;&quot;) + labs(fill = &quot;&quot;) + labs(title = &quot;Frequency of Myers-Briggs Types&quot;) + labs(subtitle = &quot;Expected among 1000 individuals | @evamaerey | Source: http://www.myersbriggs.org/&quot;) + theme_bw(base_size = 10, base_family = &quot;Times&quot;) "],
["wine.html", "Chapter 13 Wine", " Chapter 13 Wine Wine production in Europe may have been volitile during the years plotted because of production control policies implemented by the EU. The big three, Italy, France and Spain, particularly saw a lot of volitility early in this period. df &lt;- readxl::read_xlsx(&quot;raw_data/Wine_Production_by_country.xlsx&quot;) %&gt;% filter(Country != &quot;World total&quot;) Europe &lt;- c( &quot;Italy&quot;, &quot;France&quot;, &quot;Spain&quot;, &quot;Germany&quot;, &quot;Portugal&quot;, &quot;Romania&quot;, &quot;Austria&quot;, &quot;Greece&quot;, &quot;Hungary&quot; ) ggplot(df %&gt;% filter(Country %in% Europe)) + aes(x = Year) + aes(y = `Wine production in mhl`) + facet_wrap(~ fct_inorder(Country), strip.position = &quot;bottom&quot;, nrow = 1) + geom_col(aes(alpha = Year), position = &quot;dodge&quot;, fill = &quot;darkred&quot;, width = 1) + geom_line(col = &quot;black&quot;, lty = 2) + scale_y_continuous(expand = c(0, 0)) + labs(fill = &quot;&quot;) + labs(alpha = &quot;&quot;)+ labs(title = &quot;Wine production (mhl) in principle European markets, 2012-2016&quot;) + labs(subtitle = &quot;The EU program to regulate viticultural production ended upon the 2011/2012 harvest.&quot;) + labs(caption = &quot;Design: Gina Reynolds @EvaMaeRey \\nData Source: International Organisation of Vine and Wine&quot;) + # \\nProduction volitility for top producers followed. theme_classic(base_family = &quot;Times&quot;) + theme( axis.title = element_blank(), strip.placement = &quot;outside&quot;, axis.text.x = element_blank(), axis.ticks.x = element_blank(), strip.background = element_blank(), plot.caption = element_text(size = 10) ) "],
["arctic-ice.html", "Chapter 14 Arctic Ice", " Chapter 14 Arctic Ice This visualization shows the trend in Arctic Ice Sea Extent, data from the National Snow and Ice Data Center. If I recall correctly, the definition for coverage is the case where at least 15 percent of the sea is ice. The visualization shows melting and freezing cycles, in accordance with the seasons — and the disconcerting trend of a general decrease in ice extent over the years. One problem that arises is due to inconsistant number of days in each year. There is a measurement for every day, but leap years contain a extra day. Which means that plotting years over years leads to imperfect alignment. My solution was just to pretend that all the data come from a single year, 2000, and plot each of the years on that scale. The earliest year cycle and last year cycle are highlighted in white. A random sample from the data set: Date Extent (million sq km) year month_day month_day_plus proportion_ocean_covered_in_ice mean_for_day diff_from_mean_day 1982-04-14 15.627 1982 04-14 2000-04-14 0.0434083 14.629000 0.9980000 1982-12-20 14.016 1982 12-20 2000-12-20 0.0389333 12.922823 1.0931765 1996-09-17 7.531 1996 09-17 2000-09-17 0.0209194 5.915686 1.6153143 1994-05-01 14.126 1994 05-01 2000-05-01 0.0392389 13.733206 0.3927941 1981-10-12 8.630 1981 10-12 2000-10-12 0.0239722 7.562114 1.0678857 year average_coverage num_days average_day 1982 12.43945 182 1982-07-02 00:00:00 2016 10.15069 366 2016-07-01 12:00:00 # breaks for x axis. br &lt;- as.numeric(lubridate::ymd(c( &quot;2000-01-01&quot;, &quot;2000-04-01&quot;, &quot;2000-07-01&quot;, &quot;2000-10-01&quot;, &quot;2001-01-01&quot; ))) ggplot(df) + aes(x = as.numeric(month_day_plus)) + aes(y = `Extent (million sq km)`) + aes(group = year) + geom_line() + aes(col = year) + scale_x_continuous( breaks = br, labels = c(&quot;Jan-01&quot;, &quot;Apr-01&quot;, &quot;Jul-01&quot;, &quot;Oct-01&quot;, &quot;Jan-01&quot;), expand = c(0, 0) ) + scale_y_continuous(expand = c(0, 0), limits = c(0, 20)) + scale_color_continuous( guide = guide_colourbar(reverse = TRUE), breaks = seq(2010, 1980, -10) ) + geom_line(aes(lty = factor(year)), data = df %&gt;% filter(year == 2016 | year == 1982), col = &quot;white&quot; ) + scale_linetype_manual( name = &quot;&quot;, values = c(&quot;dashed&quot;, &quot;solid&quot;) ) + annotate( geom = &quot;text&quot;, x = 11210, y = 15, label = str_wrap(&quot;For this period, 1982 had the highest calendar-year average extent of Arctic sea ice while 2016 had the lowest&quot;, 30), col = &quot;white&quot;, size = 7 ) + labs(x = &quot;&quot;) + labs(y = &quot;extent (million sq km)&quot;) + labs(col = &quot;&quot;) + labs(lty = &quot;&quot;) + labs(title = &quot;Freezing cycles: Arctic sea ice extent, 1979-2017&quot;) + labs(subtitle = &quot;Data Source: National Snow &amp; Ice Data Center | Vis: Gina Reynolds for #MakeoverMonday&quot;) + theme_dark(base_size = 14) + theme( legend.background = element_blank(), legend.position = c(0.1, .35), legend.text = element_text(colour = &quot;white&quot;, size = 15), plot.background = element_rect(fill = &quot;grey30&quot;), plot.title = element_text(colour = &quot;lightgrey&quot;), plot.subtitle = element_text(colour = &quot;lightgrey&quot;), axis.title = element_text(colour = &quot;lightgrey&quot;), axis.line = element_line(colour = &quot;lightgrey&quot;), axis.text = element_text(colour = &quot;lightgrey&quot;), axis.ticks = element_line(colour = &quot;lightgrey&quot;) ) "],
["references.html", "References", " References "]
]
